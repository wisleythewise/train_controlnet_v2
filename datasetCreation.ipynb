{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\z004v4ht\\AppData\\Local\\miniconda3\\envs\\diffusers\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 13187/13187 [00:00<00:00, 77978.36it/s] \n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"imagefolder\", data_dir=\"D:/nulimages_data/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/diffusers/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\nulimages_data\\\\crop\\\\/groundTruth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m conditioning_image_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Load file paths\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m ground_truth_paths \u001b[38;5;241m=\u001b[39m \u001b[43mload_filepaths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m caption_paths \u001b[38;5;241m=\u001b[39m load_filepaths(caption_dir)  \u001b[38;5;66;03m# This assumes captions are image files; adjust if they are text files.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m conditioning_image_paths \u001b[38;5;241m=\u001b[39m load_filepaths(conditioning_image_dir)\n",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m, in \u001b[0;36mload_filepaths\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_filepaths\u001b[39m(directory):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m))]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\nulimages_data\\\\crop\\\\/groundTruth'"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, Image\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Function to load images from a directory and return a list of file paths\n",
    "def load_filepaths(directory):\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(('.png', '.jpg', '.jpeg', \".txt\"))]\n",
    "\n",
    "# Function to load text file contents\n",
    "def load_text(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "# Assuming your directories are structured within 'train'\n",
    "base_path = 'D:\\\\nulimages_data\\\\crop\\\\'\n",
    "ground_truth_dir = os.path.join(base_path, 'groundTruth')\n",
    "caption_dir = os.path.join(\"D:\\\\nulimages_data\\\\train\\\\\", 'caption')\n",
    "conditioning_image_dir = os.path.join(base_path, 'mask')\n",
    "\n",
    "# Load file paths\n",
    "ground_truth_paths = load_filepaths(ground_truth_dir)\n",
    "caption_paths = load_filepaths(caption_dir)  # This assumes captions are image files; adjust if they are text files.\n",
    "conditioning_image_paths = load_filepaths(conditioning_image_dir)\n",
    "\n",
    "# Sort the paths to ensure they are aligned\n",
    "ground_truth_paths.sort()\n",
    "caption_paths.sort()\n",
    "conditioning_image_paths.sort()\n",
    "\n",
    "# Load the text\n",
    "captions = [load_text(p) for p in caption_paths]\n",
    "\n",
    "# Verify that the counts match\n",
    "assert len(ground_truth_paths) == len(captions) == len(conditioning_image_paths), \"Mismatch in number of files\"\n",
    "\n",
    "# Combine into a single list of dictionaries\n",
    "data_dict = {\n",
    "    'groundTruth': ground_truth_paths,\n",
    "    'caption': captions,\n",
    "    'conditioning_image': conditioning_image_paths\n",
    "}\n",
    "\n",
    "\n",
    "# Create the dataset\n",
    "dataset = Dataset.from_dict(data_dict)\n",
    "dataset = dataset.cast_column(\"groundTruth\", Image())\n",
    "dataset = dataset.cast_column(\"conditioning_image\", Image())\n",
    "\n",
    "# Now your dataset has the 'train' split structured as you wanted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['groundTruth', 'caption', 'conditioning_image']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1319/1319 [00:15<00:00, 83.53 examples/s]it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:01<00:00, 12.07ba/s]\n",
      "Map: 100%|██████████| 1319/1319 [00:30<00:00, 42.88 examples/s]1, 34.57s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:01<00:00, 10.61ba/s]\n",
      "Map: 100%|██████████| 1319/1319 [00:19<00:00, 69.22 examples/s]9, 41.17s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:01<00:00, 12.85ba/s]\n",
      "Map: 100%|██████████| 1319/1319 [00:17<00:00, 76.58 examples/s]2, 37.57s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:01<00:00, 11.07ba/s]\n",
      "Map: 100%|██████████| 1319/1319 [00:20<00:00, 65.31 examples/s]3, 35.61s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:01<00:00,  9.82ba/s]\n",
      "Map: 100%|██████████| 1319/1319 [00:22<00:00, 59.84 examples/s]7, 35.40s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:01<00:00,  7.48ba/s]\n",
      "Map: 100%|██████████| 1319/1319 [00:18<00:00, 72.60 examples/s]7, 36.77s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:01<00:00,  9.12ba/s]\n",
      "Map: 100%|██████████| 1318/1318 [00:19<00:00, 68.45 examples/s]8, 36.07s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:01<00:00,  7.06ba/s]\n",
      "Map: 100%|██████████| 1318/1318 [00:15<00:00, 87.00 examples/s]3, 36.73s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:01<00:00,  9.63ba/s]\n",
      "Map: 100%|██████████| 1318/1318 [00:15<00:00, 87.54 examples/s]5, 35.26s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:01<00:00, 10.76ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 10/10 [05:56<00:00, 35.66s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/JaspervanLeuven/nulImages_cropped/commit/57982d7dee413614ac218cde995deba83d7ac558', commit_message='Upload dataset', commit_description='', oid='57982d7dee413614ac218cde995deba83d7ac558', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset.push_to_hub(\"JaspervanLeuven/nulImages_cropped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
